# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ3 ‚Äî –¢–µ–∫—Å—Ç—ã –∏ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤

**–¶–µ–ª—å:** –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –ø–æ—Å—á–∏—Ç–∞—Ç—å —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –∏ –≤—ã–≤–µ—Å—Ç–∏ —Ç–æ–ø-N.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
src/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ text.py           # –ú–æ–¥—É–ª—å —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º
‚îî‚îÄ‚îÄ lab03/
    ‚îú‚îÄ‚îÄ text_stats.py      # –°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ stdin
    ‚îî‚îÄ‚îÄ README.md          # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## –ó–∞–¥–∞–Ω–∏–µ A ‚Äî –ú–æ–¥—É–ª—å `src/lib/text.py`

–ú–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —á–µ—Ç—ã—Ä–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º:

### 1. `normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str`

–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç:
- –ü—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Å –ø–æ–º–æ—â—å—é `casefold()` (–ª—É—á—à–µ —á–µ–º `lower()` –¥–ª—è Unicode)
- –ó–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ `—ë/–Å` –Ω–∞ `–µ/–ï`
- –ó–∞–º–µ–Ω—è–µ—Ç —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (`\t`, `\r`, `\n`) –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
- –°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –æ–¥–∏–Ω
- –û–±—Ä–µ–∑–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã —Å –∫—Ä–∞—ë–≤

**–ü—Ä–∏–º–µ—Ä—ã:**
```python
normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t")           
normalize("—ë–∂–∏–∫, –Å–ª–∫–∞")               
normalize("Hello\r\nWorld")           
normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ")  
```

### 2. `tokenize(text: str) -> list[str]`

–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞). –¢–æ–∫–µ–Ω ‚Äî —ç—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ `\w+` (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ) —Å –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –¥–µ—Ñ–∏—Å–∞–º–∏ –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞.

**–ü—Ä–∏–º–µ—Ä—ã:**
```python
tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä")              
tokenize("hello,world!!!")          
tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ")     
tokenize("2025 –≥–æ–¥")                
tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ")        
```

### 3. `count_freq(tokens: list[str]) -> dict[str, int]`

–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Ç–æ–∫–µ–Ω–æ–≤.

**–ü—Ä–∏–º–µ—Ä—ã:**
```python
count_freq(["a","b","a","c","b","a"])  # ‚Üí {"a": 3, "b": 2, "c": 1}
count_freq(["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "–ø—Ä–∏–≤–µ—Ç"])  # ‚Üí {"–ø—Ä–∏–≤–µ—Ç": 2, "–º–∏—Ä": 1}
```

### 4. `top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É.

**–ü—Ä–∏–º–µ—Ä—ã:**
```python
top_n({"a": 3, "b": 2, "c": 1}, 2)       # ‚Üí [("a", 3), ("b", 2)]
top_n({"bb": 2, "aa": 2, "cc": 1}, 2)    # ‚Üí [("aa", 2), ("bb", 2)]
```

### –ö–æ–¥ –º–æ–¥—É–ª—è `text.py`

```python


import re
from typing import Dict, List, Tuple


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    
    result = text

    # –ó–∞–º–µ–Ω–∞ —ë/–Å –Ω–∞ –µ/–ï
    if yo2e:
        result = result.replace('—ë', '–µ').replace('–Å', '–ï')

    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    if casefold:
        result = result.casefold()

    # –ó–∞–º–µ–Ω–∞ —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    result = result.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')

    # –°—Ö–ª–æ–ø—ã–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –æ–¥–∏–Ω
    result = re.sub(r'\s+', ' ', result)

    # –û–±—Ä–µ–∑–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ —Å –∫—Ä–∞—ë–≤
    result = result.strip()

    return result


def tokenize(text: str) -> List[str]:
   
    # –®–∞–±–ª–æ–Ω: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å \w, –¥–æ–ø—É—Å–∫–∞—é—â–∞—è –¥–µ—Ñ–∏—Å—ã –≤–Ω—É—Ç—Ä–∏
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    return tokens


def count_freq(tokens: List[str]) -> Dict[str, int]:
    
    freq: Dict[str, int] = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq


def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á—É: (-—á–∞—Å—Ç–æ—Ç–∞, —Å–ª–æ–≤–æ)
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    import doctest
    doctest.testmod()

    # –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –º–∏–Ω–∏-—Ç–µ—Å—Ç—ã
    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤...")

    # normalize
    assert normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t") == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
    assert normalize("—ë–∂–∏–∫, –Å–ª–∫–∞") == "–µ–∂–∏–∫, –µ–ª–∫–∞"
    assert normalize("Hello\r\nWorld") == "hello world"
    assert normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ") == "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"
    print("‚úì normalize —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã")

    # tokenize
    assert tokenize("–ø—Ä–∏–≤–µ—Ç, –º–∏—Ä!") == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]
    assert tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ") == ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]
    assert tokenize("2025 –≥–æ–¥") == ["2025", "–≥–æ–¥"]
    print("‚úì tokenize —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã")

    # count_freq + top_n
    freq = count_freq(["a", "b", "a", "c", "b", "a"])
    assert freq == {"a": 3, "b": 2, "c": 1}
    assert top_n(freq, 2) == [("a", 3), ("b", 2)]
    print("‚úì count_freq —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã")

    # —Ç–∞–π-–±—Ä–µ–π–∫ –ø–æ —Å–ª–æ–≤—É –ø—Ä–∏ —Ä–∞–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ
    freq2 = count_freq(["bb", "aa", "bb", "aa", "cc"])
    assert top_n(freq2, 2) == [("aa", 2), ("bb", 2)]
    print("‚úì top_n —Ç–∞–π-–±—Ä–µ–π–∫ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã")

    print("\n–í—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–π–¥–µ–Ω—ã! ‚úì")
```

## –ó–∞–¥–∞–Ω–∏–µ B ‚Äî –°–∫—Ä–∏–ø—Ç `src/lab03/text_stats.py`

–°–∫—Ä–∏–ø—Ç —á–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ `stdin`, –≤—ã–∑—ã–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –º–æ–¥—É–ª—è `text.py` –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:
- –í—Å–µ–≥–æ —Å–ª–æ–≤
- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
- –¢–æ–ø-5 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤

### –ö–æ–¥ —Å–∫—Ä–∏–ø—Ç–∞ `text_stats.py`

```python
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ stdin –∏ –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    echo "–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞" | python text_stats.py
    cat file.txt | python text_stats.py

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
    TABLE_FORMAT=1 - –≤–∫–ª—é—á–∏—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞
"""

import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é lib –≤ sys.path
lib_path = Path(__file__).parent.parent / 'lib'
sys.path.insert(0, str(lib_path))

from text import normalize, tokenize, count_freq, top_n


def print_stats(text: str, top_count: int = 5, table_format: bool = False) -> None:
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    normalized = normalize(text)
    tokens = tokenize(normalized)
    
    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç
    freq = count_freq(tokens)
    top_words = top_n(freq, top_count)
    
    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")
    
    if table_format and top_words:
        print_table(top_words)
    else:
        print_simple(top_words)


def print_simple(top_words: list) -> None:
    print(f"–¢–æ–ø-{len(top_words)}:")
    for word, freq in top_words:
        print(f"{word}:{freq}")


def print_table(top_words: list) -> None:
    if not top_words:
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–ª–æ–≤
    max_word_len = max(len(word) for word, _ in top_words)
    word_width = max(max_word_len, len("—Å–ª–æ–≤–æ"))
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —á–∞—Å—Ç–æ—Ç
    max_freq_len = max(len(str(freq)) for _, freq in top_words)
    freq_width = max(max_freq_len, len("—á–∞—Å—Ç–æ—Ç–∞"))
    
    # –í—ã–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    print(f"\n–¢–æ–ø-{len(top_words)}:")
    print(f"{'—Å–ª–æ–≤–æ':<{word_width}} | {'—á–∞—Å—Ç–æ—Ç–∞':<{freq_width}}")
    print("-" * (word_width + freq_width + 3))
    
    # –í—ã–≤–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ
    for word, freq in top_words:
        print(f"{word:<{word_width}} | {freq:<{freq_width}}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å –≤–≤–æ–¥ –∏–∑ stdin
    try:
        text = sys.stdin.read()
    except KeyboardInterrupt:
        print("\n–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º", file=sys.stderr)
        sys.exit(1)
    
    if not text.strip():
        print("–û—à–∏–±–∫–∞: –ø—É—Å—Ç–æ–π –≤–≤–æ–¥", file=sys.stderr)
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ —Ç–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    table_format = os.environ.get('TABLE_FORMAT', '0') == '1'
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print_stats(text, top_count=5, table_format=table_format)


if __name__ == "__main__":
    main()
```

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (‚òÖ‚òÖ‚òÖ)

### 1. –§—É–Ω–∫—Ü–∏—è `strip_stopwords` (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤)

–ú–æ–¥—É–ª—å `text.py` —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤:

```python
from text import strip_stopwords

tokens = ["–ø—Ä–∏–≤–µ—Ç", "–∏", "–º–∏—Ä", "–∫–∞–∫", "–¥–µ–ª–∞"]
filtered = strip_stopwords(tokens)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "–¥–µ–ª–∞"]
```

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Å—Ç–æ–ø-—Å–ª–æ–≤.

### 2. –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–∫—Ä–∏–ø—Ç–∞ (`text_stats_advanced.py`)

–°–∫—Ä–∏–ø—Ç —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ–ø—Ü–∏—è–º–∏:
- `-n, --top N` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤
- `-s, --no-stopwords` ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
- `-m, --min-length N` ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
- `-f, --format` ‚Äî —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ (simple, table, json, csv)
- `--save FILE` ‚Äî —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª

**–ü—Ä–∏–º–µ—Ä—ã:**
```bash
# –° —É–¥–∞–ª–µ–Ω–∏–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤
cat file.txt | python3 text_stats_advanced.py -s -n 10

# JSON —Ñ–æ—Ä–º–∞—Ç
echo "–¢–µ–∫—Å—Ç" | python3 text_stats_advanced.py --format json

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
cat file.txt | python3 text_stats_advanced.py --save results.txt
```

### 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (`text_stats_visual.py`)

ASCII-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–æ–π —á–∞—Å—Ç–æ—Ç:

```bash
cat file.txt | python3 text_stats_visual.py
```

–í—ã–≤–æ–¥ –≤–∫–ª—é—á–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—É—é —Ä–∞–º–∫—É —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É.

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç

**–í–≤–æ–¥:**
```bash
echo "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!" | python3 src/lab03/text_stats.py
```

**–í—ã–≤–æ–¥:**
```
–í—Å–µ–≥–æ —Å–ª–æ–≤: 3
–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 2
–¢–æ–ø-2:
–ø—Ä–∏–≤–µ—Ç:2
–º–∏—Ä:1
```

### –ü—Ä–∏–º–µ—Ä 2: –¢–µ–∫—Å—Ç —Å —ë –∏ –¥–µ—Ñ–∏—Å–∞–º–∏

**–í–≤–æ–¥:**
```bash
echo "–Å–∂–∏–∫ –∏ –µ–∂–∏–∫ –≥—É–ª—è–ª–∏ –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –≤–µ—Å–µ–ª–æ. –Å–ª–∫–∞ –∫—Ä–∞—Å–∏–≤–∞!" | python3 src/lab03/text_stats.py
```

**–í—ã–≤–æ–¥:**
```
–í—Å–µ–≥–æ —Å–ª–æ–≤: 8
–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 7
–¢–æ–ø-5:
–µ–∂–∏–∫:2
–≤–µ—Å–µ–ª–æ:1
–≥—É–ª—è–ª–∏:1
–µ–ª–∫–∞:1
–∏:1
```

**–ü–æ—è—Å–Ω–µ–Ω–∏–µ:** –°–ª–æ–≤–∞ "–Å–∂–∏–∫" –∏ "–µ–∂–∏–∫" –±—ã–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ –æ–¥–Ω–æ —Å–ª–æ–≤–æ "–µ–∂–∏–∫", —Ç–∞–∫ –∫–∞–∫ `—ë` –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ `–µ`.

### –ü—Ä–∏–º–µ—Ä 3: –¢–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (‚òÖ)

**–í–≤–æ–¥:**
```bash
echo "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞? –ú–∏—Ä –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω, –∫–æ–≥–¥–∞ –≤—Å–µ —Ö–æ—Ä–æ—à–æ. –ü—Ä–∏–≤–µ—Ç –≤—Å–µ–º!" | TABLE_FORMAT=1 python3 src/lab03/text_stats.py
```

**–í—ã–≤–æ–¥:**
```
–í—Å–µ–≥–æ —Å–ª–æ–≤: 12
–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 9

–¢–æ–ø-5:
—Å–ª–æ–≤–æ  | —á–∞—Å—Ç–æ—Ç–∞
----------------
–ø—Ä–∏–≤–µ—Ç | 3      
–º–∏—Ä    | 2      
–≤—Å–µ    | 1      
–≤—Å–µ–º   | 1      
–¥–µ–ª–∞   | 1      
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞:**
- –®–∏—Ä–∏–Ω–∞ —Å—Ç–æ–ª–±—Ü–∞ ¬´—Å–ª–æ–≤–æ¬ª –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–æ–ø–∞
- –ö—Ä–∞—Å–∏–≤–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
- –í–∫–ª—é—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è `TABLE_FORMAT=1`

### –ü—Ä–∏–º–µ—Ä 4: –¢–µ–∫—Å—Ç —Å —É–ø—Ä–∞–≤–ª—è—é—â–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏

**–í–≤–æ–¥:**
```bash
echo -e "Hello\tWorld\n–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\r\n–Ω–∞ Python" | python3 src/lab03/text_stats.py
```

**–í—ã–≤–æ–¥:**
```
–í—Å–µ–≥–æ —Å–ª–æ–≤: 5
–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 5
–¢–æ–ø-5:
hello:1
world:1
–Ω–∞:1
–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ:1
python:1
```

## –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥—É–ª—è `text.py` –∑–∞–ø—É—Å—Ç–∏—Ç–µ:

```bash
python3 src/lib/text.py
```

–í—ã–≤–æ–¥:
```
–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤...
‚úì normalize —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã
‚úì tokenize —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã
‚úì count_freq —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã
‚úì top_n —Ç–∞–π-–±—Ä–µ–π–∫ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã

–í—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–π–¥–µ–Ω—ã! ‚úì
```

## –°–∫—Ä–∏–Ω—à–æ—Ç—ã —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã

### –°–∫—Ä–∏–Ω—à–æ—Ç 1: –ó–∞–ø—É—Å–∫ –º–æ–¥—É–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
![–¢–µ—Å—Ç—ã text.py](../../img/lab03/img01.png)

### –°–∫—Ä–∏–Ω—à–æ—Ç 2: –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä
![–¢–µ—Å—Ç—ã text_stats.py](../../img/lab03/img02.png)

## –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

1. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞:**
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `casefold()` –≤–º–µ—Å—Ç–æ `lower()` –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å Unicode
   - –°–∏–º–≤–æ–ª—ã `—ë/–Å` –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ `–µ/–ï`
   - –£–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (`\t`, `\r`, `\n`) –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
   - –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã —Å—Ö–ª–æ–ø—ã–≤–∞—é—Ç—Å—è –≤ –æ–¥–∏–Ω

2. **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:**
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ `\w+(?:-\w+)*`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å–ª–æ–≤–∞ —Å –¥–µ—Ñ–∏—Å–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É")
   - –ß–∏—Å–ª–∞ —Å—á–∏—Ç–∞—é—Ç—Å—è —Ç–æ–∫–µ–Ω–∞–º–∏
   - –≠–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è

3. **–ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç:**
   - –ü—Ä–æ—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç
   - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å O(n) –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞

4. **–¢–æ–ø-N:**
   - –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã
   - –ü—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —á–∞—Å—Ç–æ—Ç ‚Äî –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É (–≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ)
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª—é—á —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ `(-—á–∞—Å—Ç–æ—Ç–∞, —Å–ª–æ–≤–æ)`

5. **–¢–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (‚òÖ):**
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
   - –í–∫–ª—é—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è `TABLE_FORMAT=1`
   - –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏

## –¢–∏–ø–æ–≤—ã–µ –æ—à–∏–±–∫–∏ –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è

1. **`—ë` vs `–µ`:**
   - –ü—Ä–æ–±–ª–µ–º–∞: "—ë–∂–∏–∫" –∏ "–µ–∂–∏–∫" —Å—á–∏—Ç–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
   - –†–µ—à–µ–Ω–∏–µ: –∑–∞–º–µ–Ω–∞ `—ë‚Üí–µ` –≤ —Ñ—É–Ω–∫—Ü–∏–∏ `normalize()`

2. **`lower()` vs `casefold()`:**
   - –ü—Ä–æ–±–ª–µ–º–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ Unicode-—Å–∏–º–≤–æ–ª–∞–º–∏
   - –†–µ—à–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `casefold()` –≤–º–µ—Å—Ç–æ `lower()`

3. **–î–µ—Ñ–∏—Å—ã –≤ —Å–ª–æ–≤–∞—Ö:**
   - –ü—Ä–æ–±–ª–µ–º–∞: "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É" —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –¥–≤–∞ —Ç–æ–∫–µ–Ω–∞
   - –†–µ—à–µ–Ω–∏–µ: —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ `\w+(?:-\w+)*`

4. **–î–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ:**
   - –ü—Ä–æ–±–ª–µ–º–∞: "—Å–ª–æ–≤–æ‚Äî—Å–ª–æ–≤–æ" –Ω–µ —Ä–∞–∑–¥–µ–ª—è–µ—Ç—Å—è
   - –†–µ—à–µ–Ω–∏–µ: –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–∏–º–≤–æ–ª–æ–º `\w`, –ø–æ—ç—Ç–æ–º—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–ª—É–∂–∏—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã

### –°–∫—Ä–∏–ø—Ç—ã
- `text_stats.py` ‚Äî –±–∞–∑–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è)
- `text_stats_advanced.py` ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –æ–ø—Ü–∏—è–º–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (‚òÖ‚òÖ)
- `text_stats_visual.py` ‚Äî –≤–µ—Ä—Å–∏—è —Å ASCII-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π (‚òÖ‚òÖ‚òÖ)
- `test_text.py` ‚Äî —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä unit-—Ç–µ—Å—Ç–æ–≤
- `examples.sh` ‚Äî –ø—Ä–∏–º–µ—Ä—ã –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã

### –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
- `test_data.txt` ‚Äî —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (–Ω–µ–±–æ–ª—å—à–æ–π)
- `test_data_large.txt` ‚Äî –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º –æ Python
- `test_data_english.txt` ‚Äî —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ
- `test_data_mixed.txt` ‚Äî —Å–º–µ—à–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ä—É—Å—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)

## –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π

- ‚úÖ –ú–æ–¥—É–ª—å `src/lib/text.py` —Å —á–∏—Å—Ç—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
- ‚úÖ –°–∫—Ä–∏–ø—Ç `src/lab03/text_stats.py` –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ stdin
- ‚úÖ README —Å –∫–æ–¥–æ–º, –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏
- ‚úÖ –¢–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Python
- ‚úÖ –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π
- ‚úÖ –î–æ–∫—Å—Ç—Ä–∏–Ω–≥–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
- ‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã (doctest + assert)
- ‚úÖ –¢–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ (‚òÖ)
- ‚úÖ –§—É–Ω–∫—Ü–∏—è `strip_stopwords` –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å—Ç–æ–ø-—Å–ª–æ–≤ (‚òÖ‚òÖ)
- ‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–∫—Ä–∏–ø—Ç–∞ —Å –æ–ø—Ü–∏—è–º–∏ CLI (‚òÖ‚òÖ)
- ‚úÖ ASCII-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (‚òÖ‚òÖ‚òÖ)
- ‚úÖ –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—ã–≤–æ–¥–∞ (simple, table, json, csv) (‚òÖ‚òÖ‚òÖ)

## –ê–≤—Ç–æ—Ä—ã

–í—ã–ø–æ–ª–Ω–µ–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–∞ –ø–æ Python –≤ –ú–ò–°–ò–°.

