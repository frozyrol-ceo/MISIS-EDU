import re
from typing import Dict, List, Tuple, Set

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    result = text

    # –ó–∞–º–µ–Ω–∞ —ë/–Å –Ω–∞ –µ/–ï
    if yo2e:
        result = result.replace('—ë', '–µ').replace('–Å', '–ï')

    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    if casefold:
        result = result.casefold()

    # –ó–∞–º–µ–Ω–∞ —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    result = result.replace('\t', ' ').replace('\r', ' ').replace('\n', ' ')

    # –°—Ö–ª–æ–ø—ã–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –æ–¥–∏–Ω
    result = re.sub(r'\s+', ' ', result)

    # –û–±—Ä–µ–∑–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ —Å –∫—Ä–∞—ë–≤
    result = result.strip()

    return result


def tokenize(text: str) -> List[str]:
    # –®–∞–±–ª–æ–Ω: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å \w, –¥–æ–ø—É—Å–∫–∞—é—â–∞—è –¥–µ—Ñ–∏—Å—ã –≤–Ω—É—Ç—Ä–∏
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    return tokens


def count_freq(tokens: List[str]) -> Dict[str, int]:
    freq: Dict[str, int] = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq


def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á—É: (-—á–∞—Å—Ç–æ—Ç–∞, —Å–ª–æ–≤–æ)
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]


def print_test_cases():
    #–í—ã–≤–æ–¥–∏—Ç –≤—Å–µ —Ç–µ—Å—Ç-–∫–µ–π—Å—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π normalize, tokenize, count_freq + top_n
    
    print("–¢–ï–°–¢-–ö–ï–ô–°–´ –î–õ–Ø –§–£–ù–ö–¶–ò–ô –û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê")
    
    
    # –¢–µ—Å—Ç-–∫–µ–π—Å—ã –¥–ª—è normalize
    print("\n1. –§–£–ù–ö–¶–ò–Ø normalize:")
    
    
    test_cases_normalize = [
        ('"–ü—Ä–ò–≤–ï—Ç\\n–ú–ò—Ä\\t"', 'normalize("–ü—Ä–ò–≤–ï—Ç\\n–ú–ò—Ä\\t")', '"–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"', '(casefold + —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø—Ä–æ–±–µ–ª—ã)'),
        ('"—ë–∂–∏–∫, –Å–ª–∫–∞"', 'normalize("—ë–∂–∏–∫, –Å–ª–∫–∞")', '"–µ–∂–∏–∫, –µ–ª–∫–∞"', '(yo2e=True)'),
        ('"Hello\\r\\nWorld"', 'normalize("Hello\\r\\nWorld")', '"hello world"', ''),
        ('"  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "', 'normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ")', '"–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"', '')
    ]
    
    for input_desc, func_call, expected, comment in test_cases_normalize:
        print(f"‚Ä¢ –í—Ö–æ–¥: {input_desc}")
        print(f"  –í—ã–∑–æ–≤: {func_call}")
        print(f"  –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {expected}")
        if comment:
            print(f"  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment}")
        print()
    
    # –¢–µ—Å—Ç-–∫–µ–π—Å—ã –¥–ª—è tokenize
    print("\n2. –§–£–ù–ö–¶–ò–Ø tokenize:")
    print("-" * 40)
    print("(–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —É–∂–µ normalize)")
    print()
    
    test_cases_tokenize = [
        ('"–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"', 'tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä")', '["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]', ''),
        ('"hello,world!!!"', 'tokenize("hello,world!!!")', '["hello", "world"]', ''),
        ('"–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"', 'tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ")', '["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]', ''),
        ('"2025 –≥–æ–¥"', 'tokenize("2025 –≥–æ–¥")', '["2025", "–≥–æ–¥"]', ''),
        ('"–µ–º–æ—ò—ñ üòä –Ω–µ —Å–ª–æ–≤–æ"', 'tokenize("–µ–º–æ—ò—ñ üòä –Ω–µ —Å–ª–æ–≤–æ")', '["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]', '(—ç–º–æ–¥–∑–∏ –≤—ã–ø–∞–¥–∞—é—Ç)')
    ]
    
    for input_desc, func_call, expected, comment in test_cases_tokenize:
        print(f"‚Ä¢ –í—Ö–æ–¥: {input_desc}")
        print(f"  –í—ã–∑–æ–≤: {func_call}")
        print(f"  –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {expected}")
        if comment:
            print(f"  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment}")
        print()
    
    # –¢–µ—Å—Ç-–∫–µ–π—Å—ã –¥–ª—è count_freq + top_n
    print("\n3. –§–£–ù–ö–¶–ò–ò count_freq + top_n:")
    
    
    print("‚Ä¢ –¢–µ—Å—Ç 1:")
    print("  –í—Ö–æ–¥ (—Ç–æ–∫–µ–Ω—ã): [\"a\",\"b\",\"a\",\"c\",\"b\",\"a\"]")
    print("  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—á–∞—Å—Ç–æ—Ç—ã): {\"a\":3,\"b\":2,\"c\":1}")
    print("  –í—ã–∑–æ–≤: top_n(..., n=2)")
    print("  –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: [(\"a\",3), (\"b\",2)]")
    print()
    
    print("‚Ä¢ –¢–µ—Å—Ç 2 (—Ç–∞–π-–±—Ä–µ–π–∫):")
    print("  –í—Ö–æ–¥ (—Ç–æ–∫–µ–Ω—ã): [\"bb\",\"aa\",\"bb\",\"aa\",\"cc\"]")
    print("  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—á–∞—Å—Ç–æ—Ç—ã): {\"aa\":2,\"bb\":2,\"cc\":1}")
    print("  –í—ã–∑–æ–≤: top_n(..., n=2)")
    print("  –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: [(\"aa\",2), (\"bb\",2)]")
    print("  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: (–∞–ª—Ñ–∞–≤–∏—Ç–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ)")
    print()

    print("–ö–û–ù–ï–¶ –¢–ï–°–¢-–ö–ï–ô–°–û–í")



def demo():
    #–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ê–ë–û–¢–´ –§–£–ù–ö–¶–ò–ô")

    
    # –ü—Ä–∏–º–µ—Ä 1: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print("\n–ü—Ä–∏–º–µ—Ä 1: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞")
    text = "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä! –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å —á–∏—Å–ª–∞–º–∏ 2025."
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {repr(text)}")
    
    normalized = normalize(text)
    print(f"–ü–æ—Å–ª–µ normalize: {repr(normalized)}")
    
    tokens = tokenize(normalized)
    print(f"–ü–æ—Å–ª–µ tokenize: {tokens}")
    
    freq = count_freq(tokens)
    print(f"–ß–∞—Å—Ç–æ—Ç—ã: {freq}")
    
    top_words = top_n(freq, 3)
    print(f"–¢–æ–ø-3 —Å–ª–æ–≤–∞: {top_words}")
    
    # –ü—Ä–∏–º–µ—Ä 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å —ç–º–æ–¥–∑–∏
    print("\n–ü—Ä–∏–º–µ—Ä 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å —ç–º–æ–¥–∑–∏")
    text2 = "Python üòä —ç—Ç–æ –∫—Ä—É—Ç–æ! Python –æ—á–µ–Ω—å –º–æ—â–Ω—ã–π üöÄ"
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {repr(text2)}")
    
    normalized2 = normalize(text2)
    tokens2 = tokenize(normalized2)
    freq2 = count_freq(tokens2)
    top_words2 = top_n(freq2, 2)
    
    print(f"–¢–æ–∫–µ–Ω—ã: {tokens2}")
    print(f"–¢–æ–ø-2 —Å–ª–æ–≤–∞: {top_words2}")



if __name__ == "__main__":
    import sys
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        if sys.argv[1] == "--demo":
            # –†–µ–∂–∏–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            print_test_cases()
            demo()
            sys.exit(0)
        elif sys.argv[1] == "--no-cases":
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—ã–≤–æ–¥ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤
            skip_cases = True
        else:
            print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
            print("  python text.py           - –∑–∞–ø—É—Å–∫ —Å —Ç–µ—Å—Ç-–∫–µ–π—Å–∞–º–∏ –∏ —Ç–µ—Å—Ç–∞–º–∏")
            print("  python text.py --demo    - –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π")
            print("  python text.py --no-cases - —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç—ã –±–µ–∑ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤")
            sys.exit(1)
    else:
        skip_cases = False
        # –í—ã–≤–æ–¥–∏–º —Ç–µ—Å—Ç-–∫–µ–π—Å—ã –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
        print_test_cases()
    

